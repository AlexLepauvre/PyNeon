{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Gaze to video frames\n",
    "\n",
    "We will download a different neon recording containing a vieo file this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recording ID: 9265f7c1-e3ce-4108-9dd1-639305591f79\n",
      "Wearer ID: 990a3de0-5a1a-4f07-bf9b-d82369213dbf\n",
      "Wearer name: Qian\n",
      "Recording start time: 2024-07-24 16:31:22.223000\n",
      "Recording duration: 96.226 s\n",
      "                 exist              filename                                              path\n",
      "3d_eye_states     True     3d_eye_states.csv     ..\\..\\data\\OpticalFlow\\data\\3d_eye_states.csv\n",
      "blinks            True            blinks.csv            ..\\..\\data\\OpticalFlow\\data\\blinks.csv\n",
      "events            True            events.csv            ..\\..\\data\\OpticalFlow\\data\\events.csv\n",
      "fixations         True         fixations.csv         ..\\..\\data\\OpticalFlow\\data\\fixations.csv\n",
      "gaze              True              gaze.csv              ..\\..\\data\\OpticalFlow\\data\\gaze.csv\n",
      "imu               True               imu.csv               ..\\..\\data\\OpticalFlow\\data\\imu.csv\n",
      "labels            True            labels.csv            ..\\..\\data\\OpticalFlow\\data\\labels.csv\n",
      "saccades          True          saccades.csv          ..\\..\\data\\OpticalFlow\\data\\saccades.csv\n",
      "world_timestamps  True  world_timestamps.csv  ..\\..\\data\\OpticalFlow\\data\\world_timestamps.csv\n",
      "scene_video       True             video.mp4             ..\\..\\data\\OpticalFlow\\data\\video.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pyneon import NeonDataset, NeonRecording\n",
    "import pandas as pd \n",
    "\n",
    "# define path from root directory of repository\n",
    "recording_dir = '../../data/OpticalFlow/data'\n",
    "\n",
    "recording = NeonRecording(recording_dir)  \n",
    "\n",
    "print(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a scene_video object exists now. The issue with neon recordings is that event data is not naturally synched to the video. Therefore, receiving an overlay of the current gaze or alternatively, the tracking of past fixations, requires further steps.\n",
    "\n",
    "We will firstly perform a mapping of the current gaze to the video. To do this, we pick the closest timestamp within gaze.csv for every video timestamp in world_timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.map_gaze_to_video(\"../../data/OpticalFlow/output.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In calling the method, we can further specify where a pickled output is saved. Why a pickle you may ask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixation_id        x        y status\n",
      "0            1  765.012  537.417  onset\n"
     ]
    }
   ],
   "source": [
    "#load pkl\n",
    "df = pd.read_pickle(\"../../data/OpticalFlow/output.pkl\")\n",
    "print(df['fixations'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the output, we can see that our mapped gaze data is a dataframe OF dataframes. For every frame, we have a dataframe of fixations with their corresponding fixation_id, x, y-values and status.\n",
    "\n",
    "This is motivated by the possibility of multiple fixations being present in any given world frame. Even while we have an active fixation, we can still track past fixations through an optical flow algorithm. Eventually, we have multiple fixations, at ifferent locations and crucially with different status, within the same frame.\n",
    "\n",
    "The standard choice for an optical flow algorithm is Lucas-Kanade, as we mostly care for the movement of sparse points within the scene. Of course, it would be possible to alternatively compute the entire visual flow field and compute the movement of points accordingly.\n",
    "\n",
    "Tracking fixations with optical flow takes a bit of time, so make a cup of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings and ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "recording.track_fixations_with_optical_flow(\"../../data/OpticalFlow/output.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print a single 'fixations'-cell from the outer dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixation_id           x           y   status\n",
      "0           10  827.414000  431.751000   active\n",
      "1            8  833.097900  462.179871  tracked\n",
      "2            7  780.811340  415.715637  tracked\n",
      "3            5  680.597717  408.502167  tracked\n",
      "4            4  752.542114  389.270447  tracked\n"
     ]
    }
   ],
   "source": [
    "print(recording.tracked_past_fixations['fixations'][200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we now have multiple fixations that are present within the same frame. Fixation 10 is currently active, indicating that Neon interprets it as being maintained. Frames 8, 7, 5, 4 are tracked within the scene, whereas 9 and 6 have already been dropped.\n",
    "\n",
    "The logic behin the status is the following. Whenever a new frame has been detected, it gets flagged as \"onset\". For all future frames during which it is monitored, the flag changes to \"active\". The first frame in which it is no longer active, it gets flagged as \"offset\", passing it to the optical flow algorithm. While the algorithm manages to track it, the flag changes to \"tracked\". When the tracking is lost, the flag changes to \"lost\" after which it is dropped from future tracking.\n",
    "\n",
    "Calling .overlay_fixations_on_video allows us to create a video with overlaid current and past fixations. The blue dot represents the current gaze location, whereas green dots represent tracked fixations. A red central dot indicates that the current moment is not recognised as a fixation (but rather a saccade or blink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.overlay_fixations_on_video(\"../../data/OpticalFlow/overlayed.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyneon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
